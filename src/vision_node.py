import rclpy
from rclpy.node import Node
from my_robot_interfaces.srv import GetBlockPose
import numpy as np
import pyrealsense2 as rs
import yaml
import time
import cv2
import torch
import os
from PIL import Image
from scipy.spatial.transform import Rotation as R

# --- å¯¼å…¥è§†è§‰ç®—æ³•é“¾ ---
from transformers import pipeline
# å‡è®¾ä½ çš„ FoundationPose å’Œ SAM å°è£…åœ¨ estimater æ¨¡å—ä¸­
try:
    from estimater import FoundationPose, ScorePredictor, PoseRefinePredictor
    # å¦‚æœä½¿ç”¨ SAMï¼Œé€šå¸¸éœ€è¦å¯¼å…¥ç›¸åº”çš„ Predictor
    # from segment_anything import sam_model_registry, SamPredictor 
except ImportError:
    print("âŒ é”™è¯¯: æœªèƒ½åœ¨è·¯å¾„ä¸­æ‰¾åˆ° FoundationPose æˆ–ç›¸å…³ä¾èµ–")

class LegoVisionService(Node):
    def __init__(self):
        super().__init__('lego_vision_service')
        
        # 1. åŠ è½½é…ç½®è·¯å¾„
        self.declare_parameter('task_yaml', '/path/to/tasks.yaml')
        self.declare_parameter('extr_yaml', '/path/to/camera_to_base.yaml')
        self.declare_parameter('mesh_dir', '/path/to/meshes/')

        # 2. åŠ è½½å¤–å‚ T_base_cam (å›ºå®š)
        with open(self.get_parameter('extr_yaml').value, "r") as f:
            extr = yaml.safe_load(f)
            self.T_base_cam = np.array(extr["T_base_cam"], dtype=np.float32)

        # 3. åŠ è½½ä»»åŠ¡æ¨¡æ¿ (é¢„è®¾ 6D Pose)
        with open(self.get_parameter('task_yaml').value, "r") as f:
            self.task_templates = yaml.safe_load(f)["tasks"]

        # 4. åˆå§‹åŒ–ç®—æ³•é“¾ (DINO + FoundationPose)
        # GroundingDINO ç”¨äº 2D æ£€æµ‹
        self.detector = pipeline(model="IDEA-Research/grounding-dino-tiny", task="zero-shot-object-detection", device="cuda")
        
        # FoundationPose ç»„ä»¶
        self.scorer = ScorePredictor()
        self.refiner = PoseRefinePredictor()
        # æ³¨æ„ï¼šFoundationPose å®ä¾‹é€šå¸¸åœ¨ handle æ—¶æ ¹æ®ç›®æ ‡åŠ¨æ€åŠ è½½å¯¹åº”çš„ Mesh

        # 5. RealSense åˆå§‹åŒ–ä¸å¯¹é½
        self.pipeline_rs = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        profile = self.pipeline_rs.start(config)
        
        # è·å–ç›¸æœºå†…å‚ K
        intr = profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()
        self.K = np.array([[intr.fx, 0, intr.ppx], [0, intr.fy, intr.ppy], [0, 0, 1]], dtype=np.float32)
        
        # æ ¸å¿ƒï¼šå¯¹é½æ·±åº¦å›¾åˆ°å½©è‰²å›¾
        self.align = rs.align(rs.stream.color)

        # 6. å¼€å¯ Service
        self.srv = self.create_service(GetBlockPose, 'get_block_pose', self.handle_get_pose)
        self.get_logger().info("âœ… è§†è§‰è¯†åˆ« & 6D åç§»ä¿®æ­£æœåŠ¡å·²å¯åŠ¨")

    def handle_get_pose(self, request, response):
        target = request.block_name
        self.get_logger().info(f"ğŸš€ æ”¶åˆ°ä»»åŠ¡: è¯†åˆ« [{target}] å¹¶ä¿®æ­£æŠ“å–ç‚¹...")

        # A. è·å–è¯¥ç‰©ä½“åœ¨ YAML é‡Œçš„é¢„è®¾ 6D æŠ“å–åç§» (ç›¸å¯¹äºç‰©ä½“ä¸­å¿ƒ)
        template = next((t for t in self.task_templates if t["name"] == target), None)
        if not template:
            response.success = False
            return response
        T_pick_in_obj = self.make_matrix(template["pick"]["pos"], template["pick"]["orientation"])

        # B. 7 ç§’ç¨³å®šè¯†åˆ«ä¼˜åŒ–å¾ªç¯
        start_t = time.time()
        best_pose_cam = None

        while (time.time() - start_t) < 7.0:
            frames = self.pipeline_rs.wait_for_frames()
            frames = self.align.process(frames)
            color_f = frames.get_color_frame()
            depth_f = frames.get_depth_frame()
            if not color_f or not depth_f: continue

            rgb = np.asanyarray(color_f.get_data())
            depth = np.asanyarray(depth_f.get_data()).astype(np.float32) / 1000.0

            # 1. GroundingDINO æ£€æµ‹
            res = self.detector(Image.fromarray(cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)), 
                                candidate_labels=[target], threshold=0.3)
            
            if res:
                # 2. è·å– Mask (è¿™é‡Œç®€åŒ–ä¸ºç”± DINO Box ç”Ÿæˆï¼Œå¦‚æœæœ‰ SAM åˆ™åœ¨æ­¤å¤„ç”Ÿæˆåƒç´ çº§ Mask)
                box = res[0]["box"]
                mask = np.zeros(depth.shape, dtype=bool)
                mask[int(box["ymin"]):int(box["ymax"]), int(box["xmin"]):int(box["xmax"])] = True
                
                # 3. FoundationPose è§£ç®—ç‰©ä½“ä¸­å¿ƒç›¸å¯¹äºç›¸æœºä½å§¿
                try:
                    # å‡å®šä½ å·²æ ¹æ® target åŠ è½½äº†å¯¹åº”çš„ mesh é‡‡æ ·ç‚¹
                    # curr_pose = self.estimator.register(K=self.K, rgb=rgb, depth=depth, ob_mask=mask)
                    # if curr_pose is not None: best_pose_cam = curr_pose
                    pass # å®é™…è¿è¡Œæ—¶å–æ¶ˆæ³¨é‡Šå¹¶å¯¹æ¥å…·ä½“æ¥å£
                except Exception as e:
                    self.get_logger().warn(f"FP è§£ç®—å¼‚å¸¸: {e}")

            # å¯è§†åŒ–è¿›åº¦
            cv2.imshow("Vision Processing", rgb)
            cv2.waitKey(1)

        # C. åæ ‡è½¬æ¢ä¸å“åº”
        if best_pose_cam is not None:
            # 1. è®¡ç®—ç‰©ä½“çœŸå®ä¸­å¿ƒåœ¨ Base ç³»ä¸‹çš„ä½ç½®
            T_base_obj = self.T_base_cam @ best_pose_cam
            
            # 2. å°† YAML çš„ 6D æŠ“å–ç‚¹åº”ç”¨åˆ°çœŸå®ç‰©ä½“ä¸Š
            T_real_pick = T_base_obj @ T_pick_in_obj
            
            # 3. å§¿æ€çº¦æŸï¼šå¼ºåˆ¶ Roll=180, Pitch=0, æå– Yaw
            yaw = np.arctan2(T_real_pick[1, 0], T_real_pick[0, 0])
            q_final = R.from_euler('xyz', [np.pi, 0, yaw]).as_quat()

            # å¡«å…… Response
            response.real_pose.position.x = float(T_real_pick[0, 3])
            response.real_pose.position.y = float(T_real_pick[1, 3])
            response.real_pose.position.z = float(T_real_pick[2, 3])
            response.real_pose.orientation.x, response.real_pose.orientation.y, \
            response.real_pose.orientation.z, response.real_pose.orientation.w = q_final
            
            response.success = True
            self.get_logger().info(f"âœ… ä¿®æ­£å®Œæˆ: Yaw={np.degrees(yaw):.2f}Â°")
        else:
            response.success = False
            self.get_logger().error("âŒ 7ç§’è¶…æ—¶ï¼Œæœªè¯†åˆ«åˆ°ç‰©ä½“")

        return response

    def make_matrix(self, pos, quat):
        mat = np.eye(4)
        mat[:3, 3] = pos
        mat[:3, :3] = R.from_quat(quat).as_matrix()
        return mat

def main():
    rclpy.init()
    node = LegoVisionService()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.pipeline_rs.stop()
        cv2.destroyAllWindows()
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
